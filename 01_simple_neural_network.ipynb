{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eeb9805",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934c1b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kajal\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e2c76",
   "metadata": {},
   "source": [
    "## Create Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536fd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):   #(28*28)MNIST image =784 is input size, \n",
    "        super(NN, self).__init__()   #super calls initialize method of parent class(i.e, nn.Module) \n",
    "        # Lets create a network()simple 2 layer\n",
    "        # nn.Linear(in_Features, out_features )\n",
    "        self.fc1 = nn.Linear(input_size, 50)    \n",
    "        self.fc2 = nn.Linear(50, num_classes)     #hidden nodes\n",
    "        \n",
    "    # define forward method, on some input x to perform actions on layers fc1, fc2 we defined\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f5ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check: if it runs and gives correct output on some random generated data\n",
    "# #initialze model\n",
    "# model = NN(784, 10)   #input size, and num_classes=10(num of digits in mnist)\n",
    "# x = torch.randn(64, 784)  #initialze x, 64:num of examples will run simultaneously\n",
    "# print(model(x).shape)  #should get 64*10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40660a1e",
   "metadata": {},
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5e4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207657e9",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a082df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a17be",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833a6d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\MyStudy\\\\pytorch_tutorial'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5e5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where to store dataset:your cwd -> make folder 'dataset'\n",
    "#When it loads the data its going to be numpy array, so transform to tensor to run in pytorch\n",
    "#download = True : if dataset is exist in current folder, don't download, else download\n",
    "train_dataset = datasets.MNIST(root = 'dataset/', train = True, transform = transforms.ToTensor(), download = True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataset = datasets.MNIST(root = 'dataset/', train = False, transform = transforms.ToTensor(), download = True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6facb3cd",
   "metadata": {},
   "source": [
    "## Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92bf580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f9691",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554cdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()       #LOss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)   #optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6dc39",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419552a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## one epoch : network has seen all the images in the dataset\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):   #goes through each batch in train loader\n",
    "        #enumerate : to see which batch index we have\n",
    "        #(data, target) : tuple, data:input images, target:correct digits for each label\n",
    "        #Get data to cuda if possible\n",
    "        data = data.to(device=device)#make the data which is currently in tensor to the device that we are using\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        #print(data.shape)\n",
    "        ## ([64,1,28,28]) : Number of input images, number of channel(as its black and white), height8width\n",
    "        ## We want 28*28=784 vector, hence need to unroll this matrix to vector\n",
    "        ## Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        data.shape\n",
    "        \n",
    "        # Forward part of NN\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backword propagation\n",
    "        optimizer.zero_grad()    # so that it doesn't store the back calculations of previous forward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient descent or adama stem\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d796b1",
   "metadata": {},
   "source": [
    "## Check accuracy on training & test to see how good our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d173ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking accuracy on training data\n",
      "Got 59058/60000 with accuracy 98.43\n",
      "checking accuracy on test data\n",
      "Got 9706/10000 with accuracy 97.06\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):      #import loader and the model\n",
    "    if loader.dataset.train:\n",
    "        print('checking accuracy on training data')\n",
    "    else:\n",
    "        print('checking accuracy on test data')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)          #can set 0/1 : as max score will of 2D\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)      #64\n",
    "        \n",
    "        print(f'Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    model.train()\n",
    "\n",
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
